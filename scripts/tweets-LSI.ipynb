{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 30 days\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['un', 'una', 'unas', 'unos', 'uno', 'sobre']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"../data/spanish_stop_words.txt\", 'rU')\n",
    "spanish_stop = []\n",
    "for line in f:\n",
    "    spanish_stop.append(line.rstrip())\n",
    "f.close()\n",
    "spanish_stop[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tweets(input_path):\n",
    "    docs = []\n",
    "    f = open(input_path, 'rU')\n",
    "    for line in f:\n",
    "        docs.append(line.rstrip())       \n",
    "    f.close()    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bot tweets loaded 9208\n",
      "nuber of human tweets loaded 33416\n"
     ]
    }
   ],
   "source": [
    "bot_tweets = get_tweets(\"../data/tweets/botTexts.txt\")\n",
    "human_tweets = get_tweets(\"../data/tweets/humanText.txt\")\n",
    "\n",
    "print \"number of bot tweets loaded\", len(bot_tweets)\n",
    "print \"nuber of human tweets loaded\", len(human_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_bot_tweets = []\n",
    "for i, bot_tweet in enumerate(bot_tweets):\n",
    "    if i%2 == 0:\n",
    "        clean_bot_tweets.append(bot_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_human_tweets = []\n",
    "for i, human_tweet in enumerate(human_tweets):\n",
    "    if i%2 == 0:\n",
    "        clean_human_tweets.append(human_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of human tweets 16708\n",
      "number of bot tweets 4604\n"
     ]
    }
   ],
   "source": [
    "print \"number of human tweets\", len(clean_human_tweets)\n",
    "print \"number of bot tweets\", len(clean_bot_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thefile = open('../data/clean_bot_tweets.txt', 'w')\n",
    "for tweet in clean_bot_tweets:\n",
    "    thefile.write(\"%s\\n\" % tweet)\n",
    "thefile = open('../data/clean_human_tweets.txt', 'w')\n",
    "for tweet in clean_human_tweets:\n",
    "    thefile.write(\"%s\\n\" % tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF and LSI definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSI(input_human_tweets, input_bot_tweets, stop_words = None):\n",
    "    tweets = input_bot_tweets + input_human_tweets\n",
    "    count_vect = CountVectorizer(min_df = 1, analyzer = \"word\", stop_words=stop_words, ngram_range = (1,2))\n",
    "    X_train_counts = count_vect.fit_transform(tweets)\n",
    "\n",
    "\n",
    "    tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "    X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=4, n_iter=7, random_state=42)\n",
    "    svd_articles = svd.fit_transform(X_train_tf)\n",
    "    articles_svd_df = pd.DataFrame(svd_articles)\n",
    "    articles_svd_df.rename(columns=lambda x: \"pc\" + str(x), inplace=True)\n",
    "    \n",
    "    articles_svd_df[\"source\"] = \"human\"    \n",
    "    articles_svd_df[\"source\"][:len(input_bot_tweets)] = \"bot\"\n",
    "    articles_svd_df[\"tweet\"] = tweets\n",
    "    \n",
    "    return articles_svd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI on raw tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myazdaniUCSD/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "raw_tweets_LSI = LSI(input_human_tweets = clean_human_tweets, input_bot_tweets = clean_bot_tweets)\n",
    "#raw_tweets_LSI.to_csv(\"../results/LSI.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_bot_tweets[3][:2] == 'RT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_rt_bot_tweets = []\n",
    "for tweet in clean_bot_tweets:\n",
    "    if tweet[:2] != \"RT\":\n",
    "        no_rt_bot_tweets.append(tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_rt_human_tweets = []\n",
    "for clean_human_tweet in clean_human_tweets:\n",
    "    if clean_human_tweet[:2] != \"RT\":\n",
    "        no_rt_human_tweets.append(clean_human_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myazdaniUCSD/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "no_rt_LSI = LSI(input_human_tweets = no_rt_human_tweets, input_bot_tweets = no_rt_bot_tweets)\n",
    "#no_rt_LSI.to_csv(\"../results/LSI-no-rt.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_counts = np.sum(X_train_counts, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_counts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[   1,    1,    1, ..., 3283, 4494, 4759]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(total_counts,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'co'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()[1540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3177, 1540, 6144, 1869])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.argsort(-total_counts)).squeeze()[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Se Vuelve Tendencia Nacional En Redes Tras Informe De CNDH https://t.co/u8DFQ9hVsC'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = no_rt_bot_tweets[3]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'se vuelve tendencia nacional en redes tras informe de cndh '"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_free_bot_tweets = [re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet.lower()) for tweet in no_rt_bot_tweets]\n",
    "url_free_human_tweets = [re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet.lower()) for tweet in no_rt_human_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_free_tweets = url_free_bot_tweets + url_free_human_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_stop_words = spanish_stop + [\"tanhuato\", 'cndh', 'ddhh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myazdaniUCSD/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "url_free_LSI = LSI(input_human_tweets = url_free_human_tweets, input_bot_tweets = url_free_bot_tweets, \n",
    "                   stop_words= spanish_stop)\n",
    "url_free_LSI.to_csv(\"../results/LSI-no-url.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count number of words and stop words for bots vs humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Informe sobre Tanhuato corrobora uso de tortura: Martnez Neri',\n",
       " 'Informe sobre Tanhuato corrobora uso de tortura: Martnez Neri',\n",
       " 'Informe sobre Tanhuato corrobora uso de tortura: Martnez Neri https://t.co/6nG9wCDx6w',\n",
       " 'Se Vuelve Tendencia Nacional En Redes Tras Informe De CNDH https://t.co/u8DFQ9hVsC',\n",
       " '\"Tanhuato\" was a trending topic in Mexico at rank 10 for duration 1h:45m .',\n",
       " 'Informe sobre Tanhuato corrobora uso de tortura: Martnez Neri https://t.co/2ZCFTrI0Ge',\n",
       " 'Confirma CNDH que Polica Federal ejecut a 22 en Tanhuato Michoacn https://t.co/FB3uQlxDDd',\n",
       " 'https://t.co/K466ZctXSS RT https://t.co/cIS3jFyWL4',\n",
       " '#Reformenlareforma y resolvamos civilizadamente este tema por favor. https://t.co/IuwvYnFNdC',\n",
       " 'Informe sobre Tanhuato corrobora uso de tortura: Martnez Neri']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_rt_bot_tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Informe sobre Tanhuato corrobora uso de tortura: Martnez Neri https://t.co/pm1xTKHpq6',\n",
       " 'Miren cmo est el acoso en Twitter a quienes nos atrevimos a publicar la verdad sobre la masacre de #Tanhuato https://t.co/8Ye4dCyqdK',\n",
       " 'Leer y saber para decir basta, #CNDH divulga masacre policiaca https://t.co/6d22eFHBtF',\n",
       " '@RFormulaQROO cheque los tuit de Isabel Miranda sobre #Tanhuato valen la pena',\n",
       " 'Abuso de autoridad, peritajes a modo: las claves del informe sobre ejecuciones en Tanhuato https://t.co/V1WMKFtxFe va @Pajaropolitico',\n",
       " '@Alejandro_Marti Por qu no inconformarnos con la masacre de Tanhuato Sr. Mart?',\n",
       " 'https',\n",
       " 'Ejecuciones en Tanhuato https://t.co/CXfRMOnWSK Opinin de @rivapa',\n",
       " 'Rechaza CNSeguridadmx ejecuciones arbitrarias en caso #Tanhuato https://t.co/OIRrpMCmJy',\n",
       " 'Entre #Tanhuato, #Nochixtln, #Ayotzinapa, la #CNTE, @Javier_Duarte, @betoborge, @GoberDuarte  y el 2018, nos estamos hundiendo como Pas.']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_rt_human_tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bot_num_chars = [len(tweet) for tweet in no_rt_bot_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Number of characters in human tweets vs bot tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_num_chars = [len(tweet) for tweet in no_rt_human_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bot_num_chars)/len(no_rt_bot_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(human_num_chars)/len(no_rt_human_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
